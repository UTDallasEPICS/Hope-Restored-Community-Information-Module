{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse PDF File for table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries \n",
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_path = \"..\\..\\public\\client_files\\collin-college\\collin.pdf\"  # Insert the path to the PDF file\n",
    "csv_file_path = \"..\\..\\public\\client_files\\collin-college\\collin_college.csv\"  # Insert the path to the CSV file\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    extracted_text = \"\"\n",
    "    tables = []\n",
    "\n",
    "    for page_num, page in enumerate(pdf.pages):\n",
    "        extracted_text += page.extract_text() + \"\\n\\n\"\n",
    "        tables_on_page = page.extract_tables()\n",
    "\n",
    "        if tables_on_page:\n",
    "            for table in tables_on_page:\n",
    "                tables.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, table in enumerate(tables):\n",
    "    print(f\"\\nTable {i + 1}:\")\n",
    "    for row in table:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "\n",
    "for table in tables:\n",
    "    for row in table:\n",
    "        all_rows.append(row)\n",
    "\n",
    "split_tables = []\n",
    "current_table = []\n",
    "\n",
    "\n",
    "for row in all_rows:\n",
    "    if len(row) > 2 and row[2] == \"Phone\":\n",
    "        if current_table:\n",
    "            split_tables.append(current_table)\n",
    "        current_table = [row]\n",
    "    else:\n",
    "        current_table.append(row)\n",
    "\n",
    "if current_table:\n",
    "    split_tables.append(current_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, split_table in enumerate(split_tables):\n",
    "    print(f\"\\nSplit Table {i + 1}:\")\n",
    "    for row in split_table:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tables = []\n",
    "extraneous_tables = []\n",
    "for i, split_table in enumerate(split_tables):\n",
    "    filtered_table = []\n",
    "    extraneous_table = []\n",
    "    for row in split_table:\n",
    "        if any(cell not in [None, \"\"] for cell in row):\n",
    "            if any(cell in [None, \"\"] for cell in row) or len(row) < 3:\n",
    "                extraneous_table.append(row.copy())\n",
    "            else:\n",
    "                filtered_table.append(row.copy())\n",
    "\n",
    "    print(f\"\\nSplit Table {i + 1} (after removing empty rows):\")\n",
    "    for row in filtered_table:\n",
    "        print(row)\n",
    "    print(f\"\\nExtra Table {i + 1} (need to augment the split table):\")\n",
    "    for row in extraneous_table:\n",
    "        print(row)\n",
    "\n",
    "    filtered_tables.append(filtered_table)\n",
    "    extraneous_tables.append(extraneous_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenting the extra to the split table\n",
    "index = next(i for i, row in enumerate(filtered_tables[4]) if \"National Autism\" in row[0])\n",
    "print(filtered_tables[4][index][1], \"\\n\")\n",
    "filtered_tables[4][index][1] += \"\\n\" + [\" \".join(row[1] for row in extraneous_tables[4])][0]\n",
    "print(filtered_tables[4][index][1], \"\\n\")\n",
    "\n",
    "index = next(i for i, row in enumerate(filtered_tables[5]) if \"Life Path\" in row[0])\n",
    "print(filtered_tables[5][index][1], \"\\n\")\n",
    "filtered_tables[5][index][1] += \" \" + [\" \".join(extraneous_tables[5][i][0] for i in range(0, 4))][0]\n",
    "print(filtered_tables[5][index][1], \"\\n\")\n",
    "\n",
    "\n",
    "filtered_tables[8].append(extraneous_tables[8][0])\n",
    "print(filtered_tables[8], \"\\n\")\n",
    "\n",
    "index = next(i for i, row in enumerate(filtered_tables[9]) if \"Medical City\" in row[0])\n",
    "print(filtered_tables[9][index][0], \"\\n\")\n",
    "filtered_tables[9][index][0] += \"\\n\" + [\" \".join(extraneous_tables[9][i][0] for i in range(0, 2))][0]\n",
    "filtered_tables[9][index][0] += \"\\n\" + extraneous_tables[9][2][0].replace(\"\\n\", \"\")\n",
    "print(filtered_tables[9][index][0], \"\\n\")\n",
    "\n",
    "index = next(i for i, row in enumerate(filtered_tables[12]) if \"Collin County Health Care Services\" in row[0])\n",
    "print(filtered_tables[12][index][0], \"\\n\")\n",
    "filtered_tables[12][index][0] += extraneous_tables[12][0][0]\n",
    "print(filtered_tables[12][index][0], \"\\n\")\n",
    "\n",
    "index = next(i for i, row in enumerate(filtered_tables[12]) if \"Womenâ€™s Veteran\" in row[0])\n",
    "print(filtered_tables[12][index][0], \"\\n\")\n",
    "filtered_tables[12][index][0] += extraneous_tables[12][1][0]\n",
    "print(filtered_tables[12][index][0], \"\\n\")\n",
    "\n",
    "index = next(i for i, row in enumerate(filtered_tables[13]) if \"Islamic\" in row[0])\n",
    "print(filtered_tables[13][index][1], \"\\n\")\n",
    "filtered_tables[13][index][1] += \"\\n\" + [\"\\n\".join(extraneous_tables[13][i][1] for i in range(0, 4))][0]\n",
    "print(filtered_tables[13][index][1], \"\\n\")\n",
    "\n",
    "filtered_tables[13].append(extraneous_tables[13][4])\n",
    "print(filtered_tables[13], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_table = [[\n",
    "    [cell.replace('\\n', ' ') if idx == 1 else cell for idx, cell in enumerate(row)] \n",
    "    for row in filtered_table\n",
    "] for filtered_table in filtered_tables]\n",
    "\n",
    "for i, test_table in enumerate(filtered_table):\n",
    "    print(f\"\\nTest Table {i + 1}:\")\n",
    "    for row in test_table:\n",
    "        print(row[1]) if len(row) > 1 else print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "def is_url(url):\n",
    "    try:\n",
    "        result = urlparse(url, scheme=\"https\")\n",
    "        result = urlparse(result.geturl().replace(\"///\", \"//\"))\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "link_start_condition = lambda line: bool(line) and \"www\" in line or \"http\" in line or \".org\" in line\n",
    "link_possible_condition = lambda line: bool(line) and \"/\" in line or \"-\" in line or \"aspx\" in line or \".com\" in line\n",
    "link_condition = lambda link: bool(link) and is_url(link) \\\n",
    "    and link[-1] != \".\" and not '@' in link\n",
    "\n",
    "email_condition = lambda line: bool(line) and \"@\" in line\n",
    "email_end_condition = lambda line: bool(line) and len(line) > 3 and \\\n",
    "    line[-4] == \".\" and all(char.isalpha() for char in line[-3:]) or \"org\" in line\n",
    "\n",
    "phone_regex = r\"((?:\\+\\d{1}[-\\.\\s]??|\\d{4}[-\\.\\s]??)?(?:\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\w{4}))\"\n",
    "phone_extra_condition = lambda line: bool(line) and line[0] == \"(\" and line[-1] == \")\"\n",
    "\n",
    "address_start_condition = lambda line: bool(line) and line[0].isdigit() and \\\n",
    "    len(line) > 5 and not \"-\" in line\n",
    "address_condition = lambda address: bool(address) and address[0].isdigit() and \\\n",
    "    len(address) > 5 and all(char.isdigit() for char in address[-5:])\n",
    "\n",
    "def process_first_column(row):\n",
    "    lines = [line.strip() for line in row[0].split(\"\\n\")]\n",
    "\n",
    "    name = \"\"\n",
    "    line_iter = 0\n",
    "    while lines:\n",
    "        line = lines[0]\n",
    "        if link_start_condition(line) or address_start_condition(line) \\\n",
    "            or email_condition(line) or line_iter >= 2:\n",
    "            break\n",
    "        name += \" \" + lines.pop(0)\n",
    "        line_iter += 1\n",
    "\n",
    "    links = []\n",
    "    addresses = []\n",
    "    others = []\n",
    "    emails = []\n",
    "    prev_link = \"\"\n",
    "    prev_address = \"\"\n",
    "    while lines:\n",
    "        if email_condition(lines[0]):\n",
    "            emails.append(lines.pop(0))\n",
    "            continue\n",
    "        line = lines[0]\n",
    "        if address_condition(prev_address):\n",
    "            addresses.append(prev_address)\n",
    "            prev_address = \"\"\n",
    "        if address_start_condition(line):\n",
    "            if link_condition(prev_link):\n",
    "                links.append(prev_link)\n",
    "                prev_link = \"\"\n",
    "            prev_address += line\n",
    "        elif link_start_condition(line.lower()):\n",
    "            prev_link = line\n",
    "        elif bool(prev_address):\n",
    "            prev_address += \" \" + line\n",
    "        elif bool(prev_link) and link_possible_condition(line):\n",
    "            prev_link += line\n",
    "        else:\n",
    "            if link_condition(prev_link):\n",
    "                links.append(prev_link)\n",
    "            elif bool(prev_link):\n",
    "                others.append(prev_link)\n",
    "            prev_link = \"\"\n",
    "            if address_condition(prev_address):\n",
    "                addresses.append(prev_address)\n",
    "            elif bool(prev_address):\n",
    "                others.append(prev_address)\n",
    "            prev_address = \"\"\n",
    "            others.append(line)\n",
    "        lines.pop(0)\n",
    "    links.append(prev_link) if bool(prev_link) else None\n",
    "    addresses.append(prev_address) if bool(prev_address) else None\n",
    "\n",
    "    return (\n",
    "        [link.replace(\" \", \"\") for link in links],\n",
    "        addresses,\n",
    "        emails,\n",
    "        name.strip(),\n",
    "        others,\n",
    "    )\n",
    "\n",
    "def process_second_column(row):\n",
    "    return row[1].replace('\\n', ' ').strip()\n",
    "\n",
    "def process_third_column(row):\n",
    "    lines = [line.strip() for line in row[2].split(\"\\n\")]\n",
    "\n",
    "    emails = []\n",
    "    phones = []\n",
    "    links = []\n",
    "    others = []\n",
    "    prev_email = \"\"\n",
    "    prev_link = \"\"\n",
    "    prev_descriptor = \"\"\n",
    "\n",
    "    while lines:\n",
    "        possible_phone = re.findall(phone_regex, lines[0])\n",
    "        if possible_phone:\n",
    "            phone = possible_phone[0]\n",
    "            lines.pop(0)\n",
    "            if(lines and phone_extra_condition(lines[0])):\n",
    "                phone += \" \" + lines.pop(0)\n",
    "            if(bool(prev_descriptor)):\n",
    "                phones.append(phone + \" [\" + prev_descriptor + \"]\")\n",
    "            elif(lines and len(lines[0]) < 9):\n",
    "                phones.append(phone + \" [\" + lines.pop(0) + \"]\")\n",
    "            else:\n",
    "                phones.append(phone)\n",
    "            continue\n",
    "        if bool(prev_descriptor):\n",
    "            others.append(prev_descriptor)\n",
    "            prev_descriptor = \"\"\n",
    "        line = lines[0]\n",
    "        if bool(prev_email) and email_end_condition(line):\n",
    "            prev_email += line\n",
    "        elif bool(prev_link) and link_possible_condition(line):\n",
    "            prev_link += line\n",
    "        elif email_condition(line):\n",
    "            prev_email = line\n",
    "        elif link_start_condition(line.lower()):\n",
    "            prev_link = line\n",
    "        else:\n",
    "            if link_condition(prev_link):\n",
    "                links.append(prev_link)\n",
    "            elif bool(prev_link):\n",
    "                others.append(prev_link)\n",
    "            if email_condition(prev_email):\n",
    "                emails.append(prev_email)\n",
    "            elif bool(prev_email):\n",
    "                others.append(prev_email)\n",
    "            prev_link = \"\"\n",
    "            prev_email = \"\"\n",
    "            prev_descriptor = line\n",
    "        lines.pop(0)\n",
    "    links.append(prev_link) if bool(prev_link) else None\n",
    "    others.append(prev_descriptor) if bool(prev_descriptor) else None\n",
    "    emails.append(prev_email) if bool(prev_email) else None\n",
    "\n",
    "    return (\n",
    "        [link.replace(\" \", \"\") for link in links],\n",
    "        emails,\n",
    "        phones,\n",
    "        others,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = []\n",
    "types = [\n",
    "    \"Community Resources\",\n",
    "    \"Adult Shelters\",\n",
    "    \"Youth Only Shelters\",\n",
    "    \"Transitional Living Programs\",\n",
    "    \"Support Groups\",\n",
    "    \"Counseling Services\",\n",
    "    \"Domestic Violence Services\",\n",
    "    \"Drug Treatment Referrals\",\n",
    "    \"Gay, Lesbian, Bisexual and Transgender\",\n",
    "    \"Psychiatric Hospitals\",\n",
    "    \"Vocation / Employment\",\n",
    "    \"Hotlines\",\n",
    "    \"Medical Referrals\",\n",
    "    \"Other Miscellaneous Referrals\",\n",
    "]\n",
    "\n",
    "for i, test_table in enumerate(filtered_table):\n",
    "    test_table = test_table[1:]\n",
    "    for row in test_table:\n",
    "        links, addresses, emails, name, others = process_first_column(row)\n",
    "        description = process_second_column(row)\n",
    "        links2, emails2, phones, others2 = process_third_column(row)\n",
    "        resources.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"links\": links + links2,\n",
    "                \"addresses\": addresses,\n",
    "                \"emails\": emails + emails2,\n",
    "                \"description\": description,\n",
    "                \"phone\": phones,\n",
    "                \"type\": [types[i]],\n",
    "                \"others\": others + others2,\n",
    "            }\n",
    "        )\n",
    "for resource in resources:\n",
    "    print(resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "import csv\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Name\", \"Links\", \"Addresses\", \"Emails\", \"Phone\", \"Type\", \"Description\"])\n",
    "    for resource in resources:\n",
    "        writer.writerow([\n",
    "            resource[\"name\"],\n",
    "            \", \".join(resource[\"links\"]),\n",
    "            \", \".join(resource[\"addresses\"]),\n",
    "            \", \".join(resource[\"emails\"]),\n",
    "            \", \".join(resource[\"phone\"]),\n",
    "            \", \".join(resource[\"type\"]),\n",
    "            resource[\"description\"],\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
